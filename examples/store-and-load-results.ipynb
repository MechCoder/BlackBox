{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Store and load `skopt` optimization results\n",
    "\n",
    "Mikhail Pak, October 2016."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.random.seed(777)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem statement\n",
    "\n",
    "We often want to store optimization results in a file. This can be useful, for example,\n",
    "\n",
    "* if you want to share your results with colleagues;\n",
    "* if you want to archive and/or document your work;\n",
    "* or if you want to postprocess your results in a different Python instance or on an another computer.\n",
    "\n",
    "The process of converting an object into a byte stream that can be stored in a file is called _serialization_.\n",
    "Conversely, _deserialization_ means loading an object from a byte stream.\n",
    "\n",
    "**Warning:** Deserialization is not secure against malicious or erroneous code. Never load serialized data from untrusted or unauthenticated sources!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple example\n",
    "\n",
    "We will use the same optimization problem as in the [`bayesian-optimization.ipynb`](https://github.com/scikit-optimize/scikit-optimize/blob/master/examples/bayesian-optimization.ipynb) notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from skopt import gp_minimize\n",
    "\n",
    "noise_level = 0.1\n",
    "\n",
    "def obj_fun(x, noise_level=noise_level):\n",
    "    return np.sin(5 * x[0]) * (1 - np.tanh(x[0] ** 2)) + np.random.randn() * noise_level\n",
    "\n",
    "res = gp_minimize(obj_fun,            # the function to minimize\n",
    "                  [(-2.0, 2.0)],      # the bounds on each dimension of x\n",
    "                  x0=[0.],            # the starting point\n",
    "                  acq_func=\"LCB\",     # the acquisition function (optional)\n",
    "                  n_calls=15,         # the number of evaluations of f including at x0\n",
    "                  n_random_starts=0,  # the number of random initialization points\n",
    "                  random_state=777)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As long as your Python session is active, you can access all the optimization results via the `res` object.\n",
    "\n",
    "So how can you store this data in a file? We will present two most common alternatives:\n",
    "\n",
    "* using the [`pickle`](https://docs.python.org/3/library/pickle.html) module;\n",
    "* using the [`joblib`](https://pythonhosted.org/joblib/) module.\n",
    "\n",
    "Of course, there also are other, less frequently used modules for data serialization, e.g. [`dill`](http://trac.mystic.cacr.caltech.edu/project/pathos/wiki/dill/User_Guide.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using `pickle`\n",
    "\n",
    "`pickle` is the most widespread data serialization library. In fact, it is a part of the Python standard library, i.e. you do not have to install any additional libraries.\n",
    "\n",
    "Let's try to pickle our result to a file named `result_pickle.pkl`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('result_pickle.pkl', 'wb') as f:\n",
    "    pickle.dump(res, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can load this file using `pickle.load()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.17487957729512074"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('result_pickle.pkl', 'rb') as f:\n",
    "    res_pickle_loaded = pickle.load(f)\n",
    "\n",
    "res_pickle_loaded.fun"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using `joblib`\n",
    "\n",
    "`joblib` is an external library for lightweight pipelining in Python. It also conveniently provides `joblib.dump()` and `joblib.load()` functions for serialization and deserialization which are optimized for large NumPy array.\n",
    "\n",
    "If you have not used it before, install joblib by typing `pip install joblib` in your terminal. The usage is very similar to the `pickle` alternative:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "with open('result_joblib.pkl', 'wb') as f:\n",
    "    joblib.dump(res, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In fact, you can skip opening the file manually and specify the filename as the second argument:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "joblib.dump(res, 'result_joblib.pkl');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `joblib.load()` to load from file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.17487957729512074"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_loaded_joblib = joblib.load('result_joblib.pkl')\n",
    "\n",
    "res_loaded_joblib.fun"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What should I use?\n",
    "\n",
    "The main advantage of `pickle` is that it is a part of the standard library. Hence, stored results can be loaded virtually everywhere, provided the same Python version. On the other side, `joblib` is better for big data; you should consider it if you have very large objects, e.g. if the number of function evaluations is very large. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Possible problems\n",
    "\n",
    "* __Python versions incompatibility:__ In general, objects serialized in Python 2 cannot be deserialized in Python 3 and vice versa. This is true for both `pickle` and `joblib`.\n",
    "* __Security issues:__ Once again, do not load any files from untrusted sources.\n",
    "* __Unable to serialize the objective function:__ This happens if your objective function is non-trivial (e.g. you call MATLAB from Python) and cannot be serialized using either of the libraries. In this case, a possible workaround is to create a deep copy of the results object and to delete the function before serializing it: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "\n",
    "res_no_fun = deepcopy(res)\n",
    "del res_no_fun.specs['args']['func']\n",
    "joblib.dump(res_no_fun, 'result_joblib_no_fun.pkl')\n",
    "\n",
    "res_loaded_no_fun = joblib.load('result_joblib_no_fun.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the objective function is missing in the loaded object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['base_estimator', 'xi', 'kappa', 'dimensions', 'n_restarts_optimizer', 'x0', 'n_random_starts', 'callback', 'n_points', 'acq_optimizer', 'n_calls', 'verbose', 'acq_func', 'y0', 'random_state'])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_loaded_no_fun.specs['args'].keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also directly delete the `.specs['args']['func']` field in the original result if you are sure you will not need it later.\n",
    "\n",
    "Be careful: If you create a (shallow) copy (i.e. `copy.copy()`) of the results object and then delete `.specs['args']['func']` in the copied object, this field will be deleted in the original object as well."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
