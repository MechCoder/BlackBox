{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimizing convolutional neural networks with scikit-optimize\n",
    "\n",
    "The goal of this example is to train a classifier that can label handwritten digits from the MNIST dataset.\n",
    "\n",
    "First, we define a convolutional neural network using the TensorFlow framework.\n",
    "\n",
    "We then use `scikit-optimize` to find a set of hyperparameters that gives good results.\n",
    "\n",
    "To simplify the construction and training of the neural network, we can use the `learn` and `layers` contrib modules from TensorFlow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import metrics\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "import tensorflow as tf\n",
    "from tensorflow.contrib import learn\n",
    "from tensorflow.contrib import layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We import the MNIST dataset and take a look at one of the labeled images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST-data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST-data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST-data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST-data/t10k-labels-idx1-ubyte.gz\n",
      "> Digit is labeled as 3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f3840430cf8>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP4AAAD7CAYAAABKWyniAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f38404c7ba8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "digits = learn.datasets.mnist.load_mnist()\n",
    "X_train, y_train = digits.train.images, digits.train.labels\n",
    "X_test, y_test = digits.test.images, digits.test.labels\n",
    "\n",
    "print('> Digit is labeled as {}'.format(y_train[1]))\n",
    "plt.matshow(np.reshape(X_train[1, :], (28, 28)), cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we define the convolutional neural network.\n",
    "We make sure to construct, train, and evaluate it inside a single function, which we will pass as an objective function to `sciki-optimize`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def tensorflow_objective(params):\n",
    "    learning_rate, batch_size, num_layers, num_channels, kernel_size, dense_size, dropout = params\n",
    "    print('Params: {}'.format(params))\n",
    "    # Used to decide whether we should use dropout\n",
    "    is_training = True\n",
    "    \n",
    "    # This function defines the custom TensorFlow model\n",
    "    def conv_model(X, y):\n",
    "        # Reshape into batches of 28x28 pixel images with 1 channel\n",
    "        X = tf.reshape(X, [-1, 28, 28, 1])\n",
    "        # Build multiple convolutional layers with max-pooling\n",
    "        for _ in range(num_layers):\n",
    "            k = kernel_size\n",
    "            X = layers.conv2d(X, num_channels, [k, k], activation_fn=tf.nn.relu)\n",
    "            X = tf.nn.max_pool(X, [1, k, k, 1], [1, k, k, 1], padding='SAME')\n",
    "\n",
    "        # Add a large dense layer\n",
    "        X = layers.flatten(X)\n",
    "        X = layers.fully_connected(X, int(dense_size), activation_fn=tf.nn.relu)\n",
    "        # Add dropout layer\n",
    "        if is_training:\n",
    "            X = tf.nn.dropout(X, dropout)\n",
    "        # Add readout layer\n",
    "        X = layers.fully_connected(X, 10, activation_fn=tf.nn.softmax)\n",
    "        # Calculate loss\n",
    "        cross_entropy = tf.reduce_mean(-tf.reduce_sum(y* tf.log(X), reduction_indices=1))\n",
    "        return X, cross_entropy\n",
    "\n",
    "    # The tf.contrib.learn package provides a scikit-learn\n",
    "    # compatible API for training TensorFlow models,\n",
    "    # which makes it easy to train and evaluate the model.\n",
    "    clf = learn.TensorFlowEstimator(\n",
    "        model_fn=conv_model,\n",
    "        n_classes=10,\n",
    "        steps=5000,\n",
    "        learning_rate=learning_rate,\n",
    "        batch_size=batch_size,\n",
    "        optimizer='Adagrad',\n",
    "    )\n",
    "\n",
    "    clf.fit(X_train, y_train)\n",
    "    is_training = False\n",
    "    score =  metrics.accuracy_score(clf.predict(X_test), y_test)\n",
    "    print('Accuracy: {}'.format(score))\n",
    "    return -score\n",
    "\n",
    "# Disable warnings\n",
    "import logging\n",
    "logger = logging.getLogger('tensorflow')\n",
    "logger.setLevel(logging.ERROR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the model is defined, we can use `scikit-optimize` to find good hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Params: [0.1, 32, 2, 32, 2, 512, 0.9]\n",
      "Accuracy: 0.9761\n",
      "Params: [0.044303752452182647, 118, 2, 35, 2, 806, 0.77481278151973654]\n",
      "Accuracy: 0.9769\n",
      "Params: [0.13981961408994042, 55, 1, 35, 4, 744, 0.87905247837090594]\n"
     ]
    }
   ],
   "source": [
    "from skopt import gp_minimize\n",
    "\n",
    "reg = GaussianProcessRegressor(alpha=1e-1)\n",
    "space  = [\n",
    "          (10**-3, 1, 'log-uniform'),  # learning_rate\n",
    "          (16, 128),                   # batch_size\n",
    "          (1, 3),                      # num_layers\n",
    "          (16, 64),                    # num_channels\n",
    "          (2, 4),                      # kernel_size\n",
    "          (256, 1024),                 # dense_size\n",
    "          (0.6, 1.0, 'uniform'),       # dropout probability\n",
    "         ]\n",
    "\n",
    "x0 = [0.1, 32, 2, 32, 2, 512, 0.9]\n",
    "res_gp = gp_minimize(tensorflow_objective, space, x0=x0, n_calls=20, random_state=0)\n",
    "\n",
    "'Best accuracy: {}'.format(-res_gp.fun)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [tf]",
   "language": "python",
   "name": "Python [tf]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
